#!/usr/bin/env python3
"""
Create document_index.json for FlockParser knowledge base.

Scans the knowledge_base directory and generates an index of documents and their chunks.
"""
import json
import os
from pathlib import Path
import re

# Configuration
KNOWLEDGE_BASE_PATH = Path("/home/joker/FlockParser/knowledge_base")
OUTPUT_PATH = Path("/home/joker/FlockParser/document_index.json")
TESTPDFS_PATH = Path("/home/joker/FlockParser/testpdfs")


def get_document_chunks():
    """Scan knowledge_base and group chunks by document ID."""
    documents = {}

    # Find all chunk files
    chunk_pattern = re.compile(r"doc_(\d+)_chunk_(\d+)\.json")

    for chunk_file in KNOWLEDGE_BASE_PATH.glob("doc_*_chunk_*.json"):
        match = chunk_pattern.match(chunk_file.name)
        if match:
            doc_id = int(match.group(1))
            chunk_num = int(match.group(2))

            if doc_id not in documents:
                documents[doc_id] = []

            documents[doc_id].append({"chunk_num": chunk_num, "file": str(chunk_file.absolute())})

    # Sort chunks by chunk number
    for doc_id in documents:
        documents[doc_id].sort(key=lambda x: x["chunk_num"])

    return documents


def get_pdf_files():
    """Get list of PDF files from testpdfs directory."""
    pdfs = []
    if TESTPDFS_PATH.exists():
        pdfs = sorted([str(p) for p in TESTPDFS_PATH.glob("*.pdf")])
    return pdfs


def create_document_index():
    """Create the document index JSON file."""
    document_chunks = get_document_chunks()
    pdf_files = get_pdf_files()

    # Build index
    index = {"documents": [], "created": "2025-10-04", "version": "1.0"}

    for doc_id in sorted(document_chunks.keys()):
        chunks = document_chunks[doc_id]

        # Try to match with actual PDF, otherwise use placeholder
        if len(pdf_files) >= doc_id:
            original_pdf = pdf_files[doc_id - 1]
        else:
            original_pdf = f"/home/joker/FlockParser/testpdfs/document_{doc_id}.pdf"

        doc_entry = {
            "id": f"doc_{doc_id}",
            "original": original_pdf,
            "chunk_count": len(chunks),
            "chunks": [{"chunk_id": c["chunk_num"], "file": c["file"]} for c in chunks],
        }

        index["documents"].append(doc_entry)

    # Write index
    with open(OUTPUT_PATH, "w") as f:
        json.dump(index, f, indent=2)

    print(f"âœ… Created document index at {OUTPUT_PATH}")
    print(f"   Documents: {len(index['documents'])}")
    for doc in index["documents"]:
        print(f"   - {doc['id']}: {doc['chunk_count']} chunks from {Path(doc['original']).name}")


if __name__ == "__main__":
    create_document_index()
